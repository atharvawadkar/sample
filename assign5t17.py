# -*- coding: utf-8 -*-
"""Assign5T17.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vxda2q6HOBlrZ6fNC1xG5t3pvW4EwkEQ
"""

import pandas as pd
df=pd.read_csv('https://raw.githubusercontent.com/shivang98/Social-Network-ads-Boost/master/Social_Network_Ads.csv')
df.sample(10)

df.drop(columns=['User ID'],inplace=True)
df.sample(10)

df.dtypes

df['Gender']=df['Gender'].astype('category')
df.dtypes

df['Gender']=df['Gender'].cat.codes
df.sample(10)

df['Gender'].value_counts()

def DetectOutlier(df,var):
  high, low = df[var].mean() + 3* df[var].std() , df[var].mean() - 3* df[var].std()
  
  print("Highest allowed in variable:", var, high)
  print("lowest allowed in variable:", var, low)
  
  count = df[(df[var] > high) | (df[var] < low)][var].count()
 
  print('Total outliers in:',var,':',count)

DetectOutlier(df,'Age')

DetectOutlier(df,'EstimatedSalary')

df.isna().sum()

import seaborn as sns
sns.heatmap(df.corr(),annot=True)

x=df[['Age','EstimatedSalary']]
y=df['Purchased']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
model.fit(x_train,y_train)
print ('Model Score:',model.score(x_test,y_test))

x=df[['Age','Gender','EstimatedSalary']]
y=df['Purchased']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
model.fit(x_train,y_train)
print ('Model Score:',model.score(x_test,y_test))

df.describe()

x=df[['Age','EstimatedSalary']]
y=df['Purchased']
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.preprocessing import MinMaxScaler
#fit Scaler on training data
norm=MinMaxScaler().fit(x_train)
#transform training data
x_train=norm.transform(x_train)
#fit Scaler on testing data
norm=MinMaxScaler().fit(x_test)
#transform testing data
x_test=norm.transform(x_test)

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
model.fit(x_train,y_train)
print ('Model Score:',model.score(x_test,y_test))

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
model.fit(x_train,y_train)
y_pred=model.predict(x_test)
print('model score:',model.score(x_test,y_test))
from sklearn.metrics import confusion_matrix
cf_matrix=confusion_matrix(y_test,y_pred)#actual o/p and predicted output
print(cf_matrix)

import seaborn as sns
sns.heatmap(cf_matrix,annot=True)

from sklearn.metrics import precision_recall_fscore_support
precision_recall_fscore_support(y_test,y_pred,average='macro')

precision_recall_fscore_support(y_test,y_pred,average='micro')

precision_recall_fscore_support(y_test,y_pred,average='weighted')

from sklearn.metrics import precision_recall_fscore_support
score=precision_recall_fscore_support(y_test,y_pred,average='micro')
print('Precision of Model:',score[0])
print('Recall of Model:',score[1])
print('F-score of Model:',score[2])